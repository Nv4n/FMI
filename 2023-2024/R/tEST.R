ip <- installed.packages()[, 1] #   показва инсталираните пакети
pfi <- setdiff(c("ggplot2", "ggpubr", "nortest", "gplots"), ip)
#   Горният ред показва кои пакети не са инсталирани
if(length(pfi) > 0) {install.packages(pfi)}

library("ggplot2")
library("ggpubr")
library("nortest")  #   Тестове за проверка на нормално разпределение
library("gplots")


#           Статистически заключения
#       Статистическите заклюения, основаващи се на случайни извадки, позволяват значително
#   да се намалят разходите за статистически изследвания на големи по обем съвкупности.
#   Информацията, получена от извадките почти винаги удовлетворява потребностите на
#   проучващите.
#       Статистическите заключения имат две основни направления:
#           - статистическо оценяване
#           - проверка на хипотези
#       И двете направления имат вероятностен характер и са свързани помежду си.

#       1. Статистическо оценяване
#           1.1. Точкови оценки
#       Точковата оценка представлява отделна величнина, получена от данните на случайна извадка,
#   която може да се доближава в различна степен до съответния параметър на популацията 
#   (генералната съвкупност). Примери за точкови оценки са  оценката на локацията и вариацията.

set.seed(950411)
x <- rnorm(n = 200, 10, 10)
x_sample <- sample(x, 150)
mean(x)   #   10.357
mean(x_sample)  #   10.91


set.seed(620331)
y <- rbinom(n = 400, size = 1, prob = 0.3)
y_sample <- sample(y, 200)
mean(y)   #   0.3175
mean(y_sample)  #   0.315



#           1.2. Интервални оценки
#       Всяка оценка, получена от случайна извавдка е обременена със случайна грешка. Основният
#   недостатък на точковата оценка се състои в това, че не позволява да се формират изводи за
#   размера на тази грешка, за точността на нейното изчисляване по отношение по отношение на 
#   обема  на вариацията на разпределението ѝ. Тази информация се съдържа в интервалната оценка.
#       

alpha <- 0.05   #   ниво на съгласие
k <- qnorm(1 - alpha/2) #   квантил

n <- length(x_sample) # размер на извадката
mean(x_sample) + k*c(-1, 1)*sd(x_sample)/sqrt(n)  #   доверителен интервал

n <- length(y_sample) # размер на извадката
mean(y_sample) + k*c(-1, 1)*sd(y_sample)/sqrt(n)  #   доверителен интервал

#           1.3. Обем  на извадката
#       Обемът на извадката е един от най-важните фактори за точността на тези оценки


mu <- mean(x)
d <- density(x)
ss <- c(34, 7, 21)
counter <- 0
par(mfrow = c(2, 2))
for(i in c(10, 30, 100)) {
    counter <- counter + 1
    plot(d, main = paste("Density plot - ", i, "obs"), xlab = "x", lwd = 2)
    set.seed(ss[counter])
    xx <- sample(x, i)
    abline(v = mu)
    abline(v = mean(xx) + k*c(-1, 0, 1)*sd(xx)/sqrt(i), col = "red", lwd = 1.5, lty = 2)
}
par(mfrow = c(1, 1))






#         2. Тестване на хипотези

#         2.1. Хипотези. Видове  хипотези

#       При статистическите хипотези се проверява правдоподобността на предварително 
#   формулирани предположения относно праметрите или вида на неизвестното разпределение 
#   в популцията. Заключенията, основаващи се на хипотезите имат вероятностен храктер.
#       Проверката на хипотеза се извършва в няколко стъпки. Стартира (първа стъпка) с 
#   формулирането на две хипотези - нулева (H0) и алтернативна (H1). Двете хипотези са 
#   взаимоизключващи се.
#       Съществуват три вида хипотези:
#           - Двустранна: H0: параметър = C / H1: параметър != C
#           - Едностранна (лявостранна): H0: параметър >= C / H1: параметър < C
#           - Едностранна (дясностранна): H0: параметър <= C / H1: параметър > C

#       Втората стъпка е да се избере нивото на съгласие (alpha). Това е вероятност, която
#   определя зоната за отхвърляне на нулевата хипотеза. Alpha се определя предварително
#   в съответствие с целите и здачите на изследването. Най-често нивото н съгласие е 0.05.
x <- seq(-4, 4, by = 0.01)
d <- dnorm(x)
alpha <- 0.05

rej <- paste0("Отхвърлям (alpha = ", alpha, ")")
criteria <- factor(rep("Не отхвърлям", length(x)), levels = c("Не отхвърлям", rej))
criteria[which(x < qnorm(alpha))] <- rej
hypothesis_greater <- qplot(x, d, geom = c("path", "area"), fill = criteria, xlab = "Z", 
                            ylab = "Плътност", main = "H0:    Параметър > C") + 
    scale_fill_manual(values = c("darkgreen", "red"))
hypothesis_greater


criteria <- factor(rep("Не отхвърлям", length(x)), levels = c("Не отхвърлям", rej))
criteria[which(x > qnorm(1 - alpha))] <- rej
hypothesis_less <- qplot(x, d, geom = c("path", "area"), fill = criteria, xlab = "Z", 
                         ylab = "Плътност", main = "H0:    Параметър < C") + 
    scale_fill_manual(values = c("darkgreen", "red"))
hypothesis_less



rej1 <- paste0("Отхвърлям (<) (alpha = ", alpha/2, ")")
rej2 <- paste0("Отхвърлям (>) (alpha = ", alpha/2, ")")
criteria <- factor(rep("Не отхвърлям", length(x)), levels = c("Не отхвърлям", rej1, rej2))
criteria[which(x > qnorm(1 - alpha/2))] <- rej2 #| x < qnorm(0.025))] <- "Отхвърлям"
criteria[which(x < qnorm(alpha/2))] <- rej1 #
hypothesis_two_sided <- qplot(x, d, geom = c("path", "area"), fill = criteria, xlab = "Z", 
                              ylab = "Плътност", main = "H0:    Параметър = C") + 
    scale_fill_manual(values = c("darkgreen", "red", "darkred"))
hypothesis_two_sided


#   В червено са изобразени критичните области, при които нулевата хипотеза се отхвърля
#   Нивото на съглсие alpha = 0.05

#       Трета и четвърта стъпка са да се определят се емперичната характеристика и след това
#   да се провери дали попада в критичната област. По-лесният вариант е да се види стойността 
#   на p-value (significance).
#       Какво по-точно представлява p-value?
#       Най-грубо казано, с подхода p-value първо оценяваме колко вероятно е емпиричнаата 
#   стойност, получена от статистическия тест при положение, че нулевата хипотеза е вярна. 
#   Критерият за взимане на решение дали да се отхвърли H0 включва сравнение на тази вероятност
#   с определеното ниво на съгласие alpha.




#         2.2. Тестове за локция/очакване на разпределението

#   Пример 1
#       Измерена е скоростта (ft/s) на 200 ярда на 30 куршума, изстреляни от пушка. Изследвайте
#   дали средната скорост на куршумите на 200 ярда е 2460 ft/s.
#   Данните са представени в множеството по-долу:

cartridge <- 
    c("30-30 WINCHESTER", "8X57MM MAUSER", "444 MARLIN", "416 RIGBY" , "307 WINCHESTER", "30-40 KRAG",
      "375 H&H; MAGNUM", "308 MARLIN EXPRESS", "6.5X55MM MAUSER", "338 MARLIN EXPRESS", "35 WHELEN",
      "375 RUGER", "7X57MM MAUSER", "416 WEATHERBY MAGNUM", "375 REMINGTON ULTRA MAGNUM", "260 REMINGTON",
      "308 WINCHESTER", "375 WEATHERBY MAGNUM", "7MM-08 REMINGTON", "8MM REMINGTON MAGNUM",
      "30 THOMPSON CENTER", "300 H&H; MAGNUM", "340 WEATHERBY MAGNUM", "270 WINCHESTER",
      "300 REMINGTON SAUM", "325 WINCHESTER SHORT MAGNUM", "7MM REMINGTON MAGNUM", 
      "300 REMINGTON ULTRA MAGNUM", "300 WEATHERBY MAGNUM", "30-378 WEATHERBY MAGNUM")
velocity <- 
    c(1608, 1624, 1654, 1960, 1875, 2018, 2051, 1873, 2165, 2195, 2101, 2052, 2222, 2153, 
      2264, 2348, 2264, 2357, 2403, 2363, 2483, 2522, 2554, 2561, 2570, 2633, 2707, 2980, 
      3005, 3017)

projectile <- data.frame(cartridge, velocity)



#   Както не веднъж сме споменавали, оценките на статистиките биват параметрични и непараметрични,
# в зависимост от вида на разпределението, за което ги изчисляваме. Параметричната статистика се 
# изпозлва при наличие на НОРМАЛНО разпределение или поне симетрично разпределение, за което нямаме
# голям брой екстремални стойности. Ето защо, първата задача е да изследваме вида на разпределението

#   Как можем да проверим едно разпределение дали е нормално или не?
par(mfrow = c(2, 2))
qqnorm(velocity); qqline(velocity)
library(help = "stats")
d <- density(velocity)
hist(velocity, main = "Хистограма", col = "red", xlab = "Golf driving distances",
     prob = T, ylim = c(0, max(d$y)))
lines(d, lw = 2)
x_axis <- seq(0.9*min(velocity), 1.11*max(velocity), length = 300)
y_axis <- dnorm(x_axis, mean = mean(velocity), sd = sd(velocity))
lines(x_axis, y_axis, col = "blue", lw = 2)

boxplot(velocity, horizontal = TRUE)
par(mfrow = c(1, 1))

ggqqplot(velocity)  # Друг начин за Q-Q plot

?shapiro.test
shapiro.test(velocity)
# Нулевата хипотеза на теста (H0) е, че разпределението е нормално
# Стойността на p-value = 0.5892 => не можем да отхвърлим H0 => 
# приемаме, че разпределението e нормално


y <- rnorm(n = length(velocity), mean = mean(velocity), sd = sd(velocity))
ks.test(x = velocity, y = y)
ks.test(x = scale(velocity), y = "pnorm")

ad.test(x = velocity)

#       Тестовете и графиките показват, че разпределението е нормално. Следователно най-добре е 
#   да използваме параметрични тестове, т.е. student t тест



#       2.1.1. Параметрични тестове за една извадка

#   H0: mean(x) = 2460
#   H1: mean(x) != 2460

#   Определяме ниво на съгласие alpha = 0.05

# x - приема вектор (задължителен параметър)
# y - приема вектор (не е задължителен)
# alternative - отговаря за типа на хипотезата и приема стойностите c("two.sided", "less", "greater")
# mu - константа, с която искаме да тестваме нулевата хипотеза

t.test(x = velocity, mu = 2460, alternative = "two.sided")
#       Стойността на p-value < alpha => отхвърляме нулевата хипотеза H0. Тоест средната 
#   не е равна на 2460 ft/s.
#       Всички t тестове ни показват и доверителните интервали на очакването. Ако проверяваната
#   стойност (mu) е извън този доверителен интервал, то отхвърляме H0 в полза на H1. 

#       Можем да порменяме големината на доверителните интервали с помощта на параметъра
#   conf.level, където посочваме с каква вероятност искаме да присъства очакването в него
t.test(x = velocity, mu = 2460, alternative = "two.sided",
       conf.level = 0.9)



#       Пример 2
#       Службата за вътрешни приходи (IRS) публикува данни за федералните данъчни декларации за 
#   доходите на физическите лица. Извадка от 12 лица от последната година показа коригираните 
#   брутни доходи в хиляди долари, които са записани във вектора
incomes <- c(9.7, 93.1, 33.0, 21.2, 81.4, 51.1, 43.5, 10.6, 12.8, 7.8, 18.1, 12.7)

#       Искаме да проверим дали физическите лица получават годишно поне 20 000 долара?

qqnorm(incomes);  qqline(incomes)
#   От Q-Q plot-а се вижда, че данните не са нормално разпределени. Ето защо ще използваме 
#   непараметрични тестове
?ggqqplot

ggqqplot(incomes)  # Друг начин за Q-Q plot
shapiro.test(incomes)
#   Използвайки Shapiro test, виждаме че променливата "income" не е нормално разпредлена.
#   Защо?
#   Защото стойността на p-value = 0.014 < alpha = 0.05 (нивото на съгласие)




#       2.1.2. Непараметрични тестове за една извадка
#   Непараметричният еквивалент на Student t тест е Wilcoxon signed rank test

#   H0: E[x] = 20
#   H1: E[x] >= 20
wilcox.test(x = incomes, alternative = "greater", mu = 20)
#       Стойността на p-value e 0.19 > alpha = 0.05 => не можем да отхвърлим H0. 

#   Параметрите в Wilcoxon теста са сходни с тези на Student t тест. Единствената разлика е 
#   параметърът conf.int, който отговаря за показването на доверителния интервал.



#       Пример 3
#       Американската асоциация на университетските преподаватели (AAUP) провежда проучвания 
#   за заплатите на професори от колежи и публикува резултатите си в годишния доклад на AAUP 
#   за икономическото състояние на професията. Да предположим, че искаме да решат дали 
#   средните заплати на преподавателите в частни и публични институции са различни. Резултатите
#   са представени във векторите по-долу
private_institutions <- c(87.3, 75.9, 108.8, 83.9, 56.6, 99.2, 54.9, 73.1, 90.6, 89.3, 84.9,
                          84.4, 129.3, 98.8, 148.1, 132.4, 75.0, 98.2, 106.3, 131.5, 41.4,
                          115.6, 60.6, 64.6, 59.9, 105.4, 74.6, 82.0, 87.2, 45.1, 116.6, 
                          106.7, 66.0, 99.6, 53.0) 

public_institutions <- c(49.9, 105.7, 116.1, 40.3, 123.1, 79.3, 72.5, 57.1, 50.7, 69.9, 40.1,
                         71.7, 73.9, 92.5, 99.9, 95.1, 57.9, 97.5, 44.9, 31.5, 49.5, 55.9, 
                         66.9, 56.9, 75.9, 103.9, 60.3, 80.1, 89.7, 86.7)


#       Първо ще започнем с изследването дали разпределенията са нормално разпределени. Ако и
#   при два вектора имаме нормални разпределения, то ще изпозлваме параметрична статистика.
#   Но, ако поне за единия вектор разпределенеито не е нормално, тогава е по-удачно да се спрем
#   на непараметрични тестове.
shapiro.test(private_institutions)
shapiro.test(public_institutions)
#   Минималната стойност на p-value за двата вектора е 0.6798 > alpha = 0.05 => разпределенията и
#   на двата вектора ги приемаме за нормални.


#       2.1.3. Параметрични тестове за две извадки - Independent Two Sample t test и
#   Welch Two sample t test  

#   Имаме два параметрични теста за проверка на локацията на две извавдки. Разликата между двата 
#   теста е предположението, че вариациите на двете извадки са с равни вариации (Independent Two 
#   Sample t test) или че не са - Welch Two Sample t test.
#   Independent Two Sample t test е по-точен от Welch Two Sample t test

#   Тест за сравняване на вариациите на две извадки от нормално разпределена популация
var.test(x = private_institutions, y = public_institutions)
#   Нулевата хипотеза H0 е, че двете извадки имат равна вариация.
#   В нашия случай, стойността на p-value = 0.6253 и следователно 


#   H0: mean(x) - mean(y) = 0
#   H1: mean(x) - mean(y) != 0


t.test(x = private_institutions, y = public_institutions, var.equal = TRUE, alternative = "two.sided")
t.test(x = private_institutions, y = public_institutions)
#       И двата теста отхвърлят нулевата хипотеза, че имаме равенство между средните стойности на
#   двете извадки (p-value = 0.0196 и p-value = 0.0188). Тоест съществува статистически значима
#   разлика между годишните заплащания на професорите в частните и публичните колежи. Разликата е
#   в полза на частните колежи.

#   Доверителният интервал е построен върху разликата от средните стойности на двете извавдки
#   и претеглена сума на вариациите.




#       Пример 4
data("mtcars")
#       Искаме да изследваме дали средната мощност на колата, измерена в конски сили hp, се 
#   различава спрямо различните трансмисии. Данните са взети от "mtcars".

am1 <- mtcars$hp[which(mtcars$am == 1)]
am0 <- mtcars$hp[which(mtcars$am == 0)]

nortest::ad.test(am1)
nortest::ad.test(am0)
#   Тестът за нормалност на разпределението отхвърля H0 при ръчните скорости (p-value = 0.00149).
#   Следователно ще използваме теста на Wilcoxon за две извадки


#       2.1.4. Непараметрични тестове за две извадки

#   H0: E(x) - E(y) = 0
#   H1: E(x) - E(y) != 0

wilcox.test(hp ~ am, data = mtcars)


#   Алтернативен начин за записване
wilcox.test(x = am1, y = am0)   
#       Този начин е по-добър от горния, понеже лесно да се прилагат алтернативните хипотези
#   "greater" и "less". В първия случай се получава неяснота при смяна на хипотезите - 
#   при коя група имаме по-голяма/по-малка стойност на локацията спрямо другата.


#       Стойността на p-value за теста е 0.0457 < 0.05 = alpha => Отхвърляме H0. Тоест
#   Съществува статистически значима разлика между очакваните мощности при колите с ръчна и
#   автоматична трансмисии. По-мощни са колите с ръчна трансмисия.

#   Доверителният интервал е построен по-много интересна формула, която няма да я обясняваме,
#   но я има :). Достатъчно е да знаем, че разликата (mu = 0) не попада в интервала.

#   Защо е важно да определим най-точно кой тест да използваме?
#   Нека същата да задача да я решим с помощта на t-test, където е важно условието за 
#   нормално разпределението на отделните групи.
t.test(hp ~ am, data = mtcars)




#           Изследване на локациите на разпределеняита при повече от две
#       групи


#       Пример 5
#       Взета е извадка от месечни наеми на апартаметни в различни региони
#   в САЩ (в долари)

Northeast <- c(1005, 898, 948, 1181, 1244)
Midwest <- c(870, 748, 699, 814, 721, 606)
South <- c(891, 630, 861, 1036)
West <- c(1025, 1012, 1090, 926, 1269)

#       Искаме да изследваме дали между някой от регионите съществува значима
#   разлика в очакването за цените в наемите.

#     Данните трябва да ги обединим в един data frame
rent_data <- data.frame(rent = c(Northeast, Midwest, South, West),
                        region = c(rep("Northeast", length(Northeast)),
                                   rep("Midwest", length(Midwest)),
                                   rep("South", length(South)),
                                   rep("West", length(West))))



#       В предишното упражнение използвахме Student t тест и Wilcoxon тест,
#   за да изследваме средните стойности и медианите на една извадката или
#   между две групи от наблюдения. 
#       За изследването на разлика между локациите на повече от две групи
#   трябва да използваме One-way ANOVA (параметричен тест) или Kruskal
#   тест (непараметричния еквавалент на ANOVA). 
#       Нека имаме n на брой вектора X1, X2, ..., Xn. Тогава имаме 
#   нулевата хипотеза Н0: E[X1] = E[X2] = ... = E[Xn] и алтернатива
#   H1: поне при една от двойките E[Xi] != E[Xj] за i != j.

#       Като всеки един параметричне тест и One-way ANOVA има своите 
#   първоначални предположения, които, ако бъдат нарушени, то трябва 
#   да използваме Kruskal тест

#       Предположения
#   1. За всяка една група, разпределението на стойностите трябва да
#   бъде нормално разпределена
#   2. Статистически еднаква дисперсия при всички групи (хомогенност на дисперсиите).



#     Ще започнем с изследване на разпределението на данните по различните 
#   групи. Най-лесно проверката ще стане с помощта на функцията aggregate.
#   Като фунцкия за агрегация ще използваме теста на Shapiro-wilk
aggregate(rent ~ region, data = rent_data, FUN = function(x) {shapiro.test(x)$p.value})

#   Минималната стойност p-value за четирите групи е 0.456 > 0.05 = alpha =>
#   не можем да отхвърлим H0 => приемаме, че и четирите групи са нормално разпределени

#     Хомогенността на дисперсиите ще проверим с помощта на теста на Бarlett,
#   с нулева хипотеза за равемство на дисперсиите между различните групи
bartlett.test(formula = rent ~ region, data = rent_data)
#   P-value = 0.6957 > 0.05 = alpha => имаме статистически равни дисперсии


#     One-way ANOVA
summary(rent_anova <- aov(formula = rent ~ region, data = rent_data))
#   С помощта на фунцкията "aov" прилагаме One-way ANOVA. Функцията съдържа
#   параметрите formula и data.
#   Стойността на p-value = 0.0023 < 0.05 = alpha => отхвърляме H0 в полза на H1 =>
#   съществува статистически значима разлика поне в някоя от двойките.


#   Остана да видим къде между кои групи са разликите. Това лесно става графично
#   с помощта на функцията plotmeans()
plotmeans(formula = rent ~ region, data = rent_data)


#   Друга опция е използването на така наречените Post-hoc pairwise контрасти,
#   които изследват взаимодействието на една група спрямо останалите.
#   Съществуват различни методи за изследването им, но ние ще се спрем само на 
#   Tukey HSD. Върнатият резултат представлява тества на разликите между 
#   всички възможни две групи, където нулевата хипотеза е, че двете локации са 
#   статистически равни (или, че разликата им е = 0)
(tukey <- TukeyHSD(rent_anova))

#   Съществените разлики при групите се забелязват в последната колона 
#   "p adj" (p-value), където искаме стойността на p-value < alpha - нивото на съгласие

#   Тоест групите между, които имаме разлика са (Northest, Midwest) и (West, Midwest)

plot(tukey) #   Графично представяне на разликите между отделните групи


#   Други методи за анализ на Post hoc pairwise са
pairwise.t.test(rent_data$rent, rent_data$region, p.adj = "bonf")
pairwise.t.test(rent_data$rent, rent_data$region, p.adj = "holm")
#       ! Различните тестове, дават различни резултати при анализа. Ето защо е важно
#   да се избере най-подходящия алгоритъм за конкретната задача.
#       Горните два теста връщат директно стойността на p-value


#     Пример 6
#     изследване на връзката между месец в годината и средните стойности на озона
#   за Ню Йорк.

data(airquality)

#   Изследване за нормално разпределние в различните групи.
aggregate(Ozone ~ Month, data = airquality, FUN = function(x) {round(shapiro.test(x)$p.value, 3)})
#   Имаме нарушение на условието за нормално разпределение на стойностите (Май и Септември)



kruskal.test(formula = Ozone ~ Month, data = airquality) 
#   Стойността на p-value за теста е 6.901e-06 << alpha = 0.05 => съществува 
#   статистически значима разлика между групите.

#     Post-hoc анализ за Kruskal-Wallis тест
pairwise.wilcox.test(airquality$Ozone, airquality$Month,
                     p.adjust.method = "BH", exact = FALSE)
#   В получената табличка са записани стойностите на p-value при изследването на 
#   разликите между групите. Така статистически значима разлика получаваме при месеците 
#   (5, 7), (5, 8), (6, 7) и т.н.




#       В края на всичко, можем да обобщим изследването на хипотези за сравняване на 
#   локацията на N на брой разпределения в следните стъпки:
#   1. Определяме броя на групите, за които ще правим проверките
#   2. Изследваме групите дали следват гаусово разпределение
#       - от тук определяме кой от тестовете ще използваме
#
#   3. Определяме хипотезата за проверка и определяме ниво на съгласие(alpha)
#
#   4. Ако ще използваме t-test или One-way ANOVA, трябва да проверим условието
#   за статистическо равенство при дисперсиите на всяка една от групите.
#       ! Ако имаме да изследваме САМО една група, тази стъпка отпада.
#
#   5. Ако при тестовете One-way ANOVA и Kruskal test имаме статистически значима
#   разлика, то е желателно да приложим и Post hoc анализ.



